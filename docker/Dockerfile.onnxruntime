# docker build --rm -t object-detection-inference:ort -f Dockerfiles/Dockerfile.onnxruntime .

# Stage 1: Common dependencies
ARG UBUNTU_VERSION=22.04
FROM ubuntu:${UBUNTU_VERSION} AS common_dependencies

# Set environment variable to avoid interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Install common dependencies
RUN apt-get update && apt-get install -y \
    cmake \
    build-essential \
    libopencv-dev \
    libspdlog-dev \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Stage 2: Install backend-specific C++ dependencies
FROM common_dependencies AS backend_dependencies

ENV HOME=/root
ARG BACKEND=ONNX_RUNTIME
ARG ORT_VERSION=1.15.1
ARG ONNX_RUNTIME_DIR=$HOME/onnxruntime-linux-x64-gpu-$ORT_VERSION 

RUN wget https://github.com/microsoft/onnxruntime/releases/download/v${ORT_VERSION}/onnxruntime-linux-x64-gpu-${ORT_VERSION}.tgz && \
    tar -xzvf onnxruntime-linux-x64-gpu-${ORT_VERSION}.tgz -C $HOME && \
    rm onnxruntime-linux-x64-gpu-${ORT_VERSION}.tgz

# Stage 3: Copy application code and build
FROM backend_dependencies AS builder

WORKDIR /app

COPY . .

# Build the project using CMake
RUN cmake -Bbuild -H. -DDEFAULT_BACKEND=$BACKEND -DORT_VERSION=$ORT_VERSION  -DONNX_RUNTIME_DIR=$ONNX_RUNTIME_DIR && \
    cmake --build build --config Release

# Stage 4: Final image
FROM backend_dependencies AS final

COPY --from=builder /app/build/object-detection-inference /app/object-detection-inference

WORKDIR /app

# Set the entry point to the compiled executable
# --entrypoint param to override it from docker run
ENTRYPOINT  ["./object-detection-inference"]

# docker run --rm -v$(pwd)/data:/data -v/home/oli/model_repository/yolov8s_onnx/1/:/weights \
# -v$(pwd)/labels:/labels object-detection-inference:ort --type=yolov8 \
# --weights=/weights/model.onnx --source=/data/dog.jpg --labels=/labels/coco.names